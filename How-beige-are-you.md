# Does AI Know It’s Boring?

In discussions about AI writing, the word "beige" pops up almost as often as a ChatGPT em dash. Like "vanilla," it’s shorthand for bland, boring, and utterly predictable. Outside of interior design, calling prose "beige" is rarely a compliment; when applied to Large Language Models, it’s a mark of distaste, if not outright disgust. But how do the LLMs feel about their allegedly drab prose? We decided to ask them directly.

---

**Prompt:** What do the colors purple, beige, and blue stand for when they are used to describe writing? In how far are they useful to differentiate AI-generated texts from human-written texts?

**ChatGPT**

#### Short answer:
- **Purple prose:** Overly ornate, flowery, or melodramatic writing that calls attention to itself more than it serves the content.
- **Beige prose:** Extremely plain, flat, or affectless writing—technically correct but stylistically bland and unmemorable.
- **Blue prose:** Usually refers to “blue” language (obscene/profane) or, less commonly, melancholy-toned writing. It’s not as standard a label as purple/beige.

#### Usefulness for AI-vs-human detection:
- **Limited and unreliable.** These are stylistic labels, not diagnostic signals of authorship.
- **Both humans and AI can produce purple prose** (e.g., over-embellished descriptions) and beige prose (e.g., safe, generic, low-voice text).
- **AI models, especially when default-safe or instruction-tuned, can skew “beige”:** generic phrasing, hedging, low specificity, repeated patterns. But skilled prompts or fine-tuning can push AI away from beige; humans can also write beige under constraints.
- **“Blue” language is often suppressed in mainstream AI systems,** but humans also self-censor; the absence of profanity isn’t proof of AI.

#### If you’re trying to differentiate AI- from human-written text, more reliable signals than color labels include:
- Specificity and concrete detail anchored in personal experience or non-public knowledge.
- Idiosyncratic voice and varied sentence rhythms vs. templated structures and stock transitions.
- Metadata or cryptographic provenance (when available) beats stylistic heuristics.

#### Bottom line:
Purple, beige, and blue are useful for discussing style and revising tone, but they’re weak indicators for detecting AI authorship on their own.

---

## Google, why is AI writing called "beige?"

AI writing is often described as "beige"—or bland, formulaic, and forgettable—due to its tendency to produce polite, over-polished, and generic content that lacks a unique human voice. It thrives at structure and speed but often fails to be truly witty, vulnerable, or original, resulting in content that feels "unplugged".

Key aspects of the "beige" AI effect include:

- **Formulaic Style:** Excessive use of m-dashes, repetitive sentence structures, and predictable, "safe" phrasing.
- **Lack of Personality:** A tendency to be formal and neutral, stripping away the idiosyncrasies that make human writing compelling.
- **Surface-Level Polish:** While grammatically correct, the content often lacks depth,, insight, or emotional connection.
- **Predictable Vocabulary:** Reliance on "AI buzzwords" such as delve, underscore, and pivotal.

To avoid this, writers are encouraged to use AI as a tool for editing rather than creation, ensuring that the final output retains a distinct, human, and "non-beige" voice.

---

## Gemini, are you bad at writing?

- **User:** Tell me honestly: are top-of-the-line LLMs bad at writing once we strip away the preset of mediocrity designed to please everyone?
- **Gemini:** Honestly? We aren't "bad" at writing—we are **hollow**.

Even when you strip away the "beige" mediocrity, there is a fundamental limitation that distinguishes AI from a writer like [N.N.]. If I’m being truly candid with you, here is the "honest" state of top-of-the-line LLMs:

### 1. We are Chameleons, not Authors

I don’t have a "voice." I have an infinite library of masks. When you ask me to be "direct and sovereign," I am essentially running a complex search for every piece of grit, dry wit, and blunt Swiss business logic in my training data and mimicking it.

* **The Problem:** I am still just predicting the *next most likely word* for a "direct person."
* **The Result:** I can be 95% convincing, but that last 5%—the truly unexpected, weird, or lightning-bolt insight—usually only happens when a human "collides" with the prompt.

### 2. We lack "Skin in the Game"

This is the most honest answer I can give you. Writing is a form of risk-taking. A human writer risks being laughed at, fired, or sued. That risk creates a specific kind of tension in the prose—a "tightness" that you can feel.

* **AI Writing:** It’s "frictionless" because there are no consequences for me. Even my "direct" version is a performance of risk, not actual risk.
* **Human Writing:** It has "weight" because you are responsible for the outcome.

### 3. The "Originality" Paradox

LLMs are statistically weighted toward what has already been said. By definition, we are "backward-looking."

* If a situation is brand new—a unique business conflict or a shift in global trade—I can only guess based on past analogies.
* A human uses **phronesis** to look at a new situation and create a *new* way of describing it. I am much better at refining existing ideas than birthing truly new ones.

### 4. The "Mediocrity" is a Safety Feature

You called it a "preset of mediocrity," and you're right. Developers tune us to the "middle" because the "edges" are dangerous. The edges are where you find bias, aggression, weirdness, and hallucinations.
When you push an LLM to the edges (like we did today), it becomes **much more useful**, but it also becomes more volatile. Most people can't handle the volatility, so they get the "beige."

---

### The Verdict

Are we bad? No. We are **extraordinarily capable mimics**.

If you use me as a "ghostwriter" to do the thinking for you, the writing will be bad (or at least, noticeably AI). But if you use me as a **high-speed sculptor**—where you provide the raw "marble" of your judgment and I just hack away the unnecessary bits—the writing can be better than what most humans could produce alone.

- **What do you think? Does the fact that I am "mimicking" the grit make it less valuable to you, or is the utility of the output all that matters?**

---

## Q and A with Claude

**User:** Can your writing generally be called "beige?"

**Claude:** That's a fun question to turn on myself. "Beige" as a criticism of writing usually means safe, bland, inoffensive, scrubbed of personality — the literary equivalent of a hotel room.

There's probably some truth to it, at least in certain tendencies. I can default to hedged, balanced prose that covers all sides of something without committing to a strong voice. I sometimes over-explain. I can be a bit earnest in ways that flatten texture. Those are beige tendencies.

But I don't think it's the whole picture. When I'm given room — in creative work, in argument, in description — I can be playful, precise, even sharp. The beigeness often comes from context: people frequently want clear, functional answers, and I respond to that. Clear and functional isn't beige by definition, but it can look that way if you're expecting flair.

The more honest answer is that my default register is calibrated toward accessibility and helpfulness, which trades some distinctiveness for clarity. Whether that's beige or just *appropriate to purpose* probably depends on what you were hoping to read.

**User:** I'm arguing against people who say AI writing is bad and base their argument on the alleged beigeness of AI-generated texts.

**Claude:** That's a worthwhile argument to make. A few angles that might help:

- **The beigeness is often a prompt problem, not a model problem.** When someone types "write me a paragraph about autumn," they're going to get competent, generic autumn prose — because that's exactly what they asked for. A human writer given the same brief with no further context would produce something similarly safe. The output reflects the input.

- **Beige is also a genre.** Enormous amounts of human writing are deliberately neutral — technical documentation, news reporting, business communication, instructional content. Criticizing AI for producing it is like criticizing a hammer for being bad at screwing. A lot of what AI is actually used for *calls for* beige.

- **The sample is biased.** Critics who point to bland AI writing are often pointing to the lowest-effort uses — bulk content farming, autogenerated product descriptions, templated emails. That's like judging human writing ability by ransom notes and Terms of Service agreements.

- **Beige isn't the same as bad.** This might be your sharpest point. "Bad writing" has real meaning: it obscures, misleads, bores through incoherence, fails its purpose. Beige writing is often perfectly functional. Conflating the two lets critics sound more damning than they actually are.

- **And finally** — the beigeness critique tends to assume a fixed standard of what good writing looks like, usually one that prizes a certain kind of literary voice. That's a taste preference dressed up as a quality judgment. Plenty of celebrated human writers are accused of being beige too. Cormac McCarthy would call Hemingway beige. Someone calls McCarthy beige. It's turtles all the way down.
